{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2371e2-20ca-4e08-9c54-a48f16ecdba6",
   "metadata": {},
   "source": [
    "Sections\n",
    "1. Imports \n",
    "2. Experimentation\n",
    "- Vanilla MPPI  \n",
    "- MPPI with HJ\n",
    "- MPPI with safety filter options\n",
    "3. Implementation\n",
    "- Success rate\n",
    "- Collision rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5c170-7ff4-47d5-93b3-b8821032001f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2d3c0-c82d-47be-96d0-6ad2d2b793e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dynamaxsys==0.0.5\n",
    "# !git clone https://github.gatech.edu/ACDS/MPPI-Generic.git\n",
    "# !pip install tqdm\n",
    "# !pip install hj-reachability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3ad50-2c73-4ba2-87c1-4e650f3de0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the dynamaxsys library to import dynamical systems implemented in JAX: https://github.com/UW-CTRL/dynamaxsys\n",
    "from dynamaxsys.unicycle import Unicycle\n",
    "from dynamaxsys.base import get_discrete_time_dynamics\n",
    "from dynamaxsys.utils import linearize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse, Circle, FancyArrow\n",
    "from scipy.stats import chi2\n",
    "import jax, jax.numpy as jnp\n",
    "\n",
    "from typing import Callable, List, Literal, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e2008-ccd6-4767-add3-e3bb86a61604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0223d5-a103-45fb-b271-f959c3170e98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Kinematic unicycle dynamics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21municycle_dynamics\u001b[39m(state, control, dt):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# -------------------------------\n",
    "# Kinematic unicycle dynamics\n",
    "# -------------------------------\n",
    "def unicycle_dynamics(state, control, dt):\n",
    "    \"\"\"\n",
    "    state  : (3,)  -> [x, y, theta]\n",
    "    control: (2,)  -> [v, omega]\n",
    "    dt     : float\n",
    "    \"\"\"\n",
    "    x, y, theta = state\n",
    "    v, omega = control\n",
    "    new_x = x + v * np.cos(theta) * dt\n",
    "    new_y = y + v * np.sin(theta) * dt\n",
    "    new_theta = theta + omega * dt\n",
    "    return np.array([new_x, new_y, new_theta])\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# MPPI controller\n",
    "# -------------------------------\n",
    "class SimpleMPPIController:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dynamics_func,\n",
    "        dt,\n",
    "        goal,\n",
    "        horizon=20,\n",
    "        n_samples=100,\n",
    "        lam=1.0, \n",
    "        noise_scale=0.3,\n",
    "        obstacle_list=None,\n",
    "        obstacle_radius=0.5,\n",
    "        collision_penalty=1e6,\n",
    "    ):\n",
    "        self.dynamics = dynamics_func\n",
    "        self.dt = dt\n",
    "        self.goal = goal\n",
    "        self.H = horizon\n",
    "        self.N = n_samples\n",
    "        self.lam = lam\n",
    "        self.noise_scale = noise_scale\n",
    "        self.u_nom = np.zeros((horizon, 2))\n",
    "        self.obstacles = obstacle_list if obstacle_list else []\n",
    "        self.obs_radius = obstacle_radius\n",
    "        self.collision_penalty = collision_penalty\n",
    "\n",
    "    def _is_collision(self, state):\n",
    "        x, y, _ = state\n",
    "        for obs in self.obstacles:\n",
    "            if np.linalg.norm([x - obs[0], y - obs[1]]) < self.obs_radius:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _trajectory_cost(self, x0, u_seq):\n",
    "        cost = 0.0\n",
    "        x = x0.copy()\n",
    "        for u in u_seq:\n",
    "            x = self.dynamics(x, u, self.dt)\n",
    "            cost += np.linalg.norm(x[:2] - self.goal)\n",
    "            if self._is_collision(x):\n",
    "                cost += self.collision_penalty\n",
    "        return cost\n",
    "\n",
    "    def step(self, x0):\n",
    "        noise = self.noise_scale * np.random.randn(self.N, self.H, 2)\n",
    "        u_rollouts = self.u_nom[None, :, :] + noise\n",
    "        costs = np.array([self._trajectory_cost(x0, u_seq) for u_seq in u_rollouts])\n",
    "\n",
    "        weights = np.exp(-costs / self.lam)\n",
    "        weight_sum = np.sum(weights)\n",
    "\n",
    "        if weight_sum == 0 or np.isnan(weight_sum):\n",
    "            weights = np.ones_like(weights) / len(weights)  # fallback to uniform weights\n",
    "        else:\n",
    "            weights /= weight_sum\n",
    "\n",
    "        u0 = np.sum(weights[:, None] * u_rollouts[:, 0], axis=0)\n",
    "\n",
    "        # shift nominal controls\n",
    "        self.u_nom = np.vstack([self.u_nom[1:], u0])\n",
    "        return u0\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Environment setup\n",
    "# -------------------------------\n",
    "dt = 0.1\n",
    "sim_steps = 150\n",
    "obstacle_radius = 0.5\n",
    "\n",
    "start_state = np.array([-2.0, -1.0, 0.0])\n",
    "goal_location = np.array([5.0, 0.0])\n",
    "\n",
    "obstacle_location = np.array([1.0, 0.0])\n",
    "obstacle_location2 = np.array([3.0, -0.5])\n",
    "obstacles = [obstacle_location, obstacle_location2]\n",
    "\n",
    "# Instantiate controller\n",
    "mppi = SimpleMPPIController(\n",
    "    dynamics_func=unicycle_dynamics,\n",
    "    dt=dt,\n",
    "    goal=goal_location,\n",
    "    horizon=10,\n",
    "    n_samples=100,\n",
    "    lam=0.6, # low lam means controller favors best trag while high lam creates smoother behavior\n",
    "    noise_scale=0.2,\n",
    "    obstacle_list=obstacles,\n",
    "    obstacle_radius=obstacle_radius,\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Simulate closed‑loop system\n",
    "# -------------------------------\n",
    "state = start_state.copy()\n",
    "states = [state]\n",
    "\n",
    "for _ in range(sim_steps):\n",
    "    u = mppi.step(state)\n",
    "    state = unicycle_dynamics(state, u, dt)\n",
    "    states.append(state)\n",
    "\n",
    "states = np.array(states)  # (sim_steps + 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49913c-6196-417f-8303-1251e3689bf1",
   "metadata": {},
   "source": [
    "### MPPI baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40665d7-eb51-4594-93c2-640484b72b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# MPPI trajectory\n",
    "ax.plot(states[:, 0], states[:, 1], linewidth=2, label=\"MPPI trajectory\")\n",
    "\n",
    "# Start and goal markers\n",
    "ax.plot(start_state[0], start_state[1], marker=\"o\", linestyle=\"\", markersize=8, label=\"Start\")\n",
    "ax.plot(goal_location[0], goal_location[1], marker=\"x\", linestyle=\"\", markersize=8, label=\"Goal\")\n",
    "\n",
    "# Obstacles (as translucent scatter points)\n",
    "ax.scatter(\n",
    "    [obstacle_location[0], obstacle_location2[0]],\n",
    "    [obstacle_location[1], obstacle_location2[1]],\n",
    "    s=(obstacle_radius * 400) ** 2 / 100.0,\n",
    "    alpha=0.3,\n",
    "    label=\"Obstacles\",\n",
    ")\n",
    "\n",
    "# Formatting\n",
    "ax.set_title(\"Unicycle Robot with MPPI Control\")\n",
    "ax.set_xlabel(\"x position (m)\")\n",
    "ax.set_ylabel(\"y position (m)\")\n",
    "ax.axis(\"equal\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ebc4d3-72e4-48dd-a489-1e56971c67cd",
   "metadata": {},
   "source": [
    "### Integrate HJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ecd95-8b00-4bdb-88d7-ea1c315f36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The HJ component estimates an approximate backward reachable set\n",
    "for each circular obstacle by inflating its radius according to the maximum\n",
    "object speed and the remaining planning time horizon.  If the simulated state\n",
    "falls inside that tube (i.e. the HJ value function becomes negative), a large\n",
    "penalty is applied so the optimizer systematically rejects unsafe rollouts.\n",
    "\"\"\"\n",
    "\n",
    "def hj_value(state: np.ndarray,\n",
    "             obstacles: list[np.ndarray],\n",
    "             obs_radius: float,\n",
    "             v_max: float,\n",
    "             remaining_steps: int,\n",
    "             dt: float) -> float:\n",
    "    \"\"\"Return the *minimum* HJ value V(x) across all obstacles.\n",
    "\n",
    "    We approximate the backward reachable tube for each obstacle by growing its\n",
    "    radius by v_max * T where T = remaining_steps * dt.  The signed‑distance\n",
    "    value function for a single obstacle then becomes\n",
    "\n",
    "        V_i(x) = dist(x, obs_i) - (obs_radius + v_max * T)\n",
    "\n",
    "    The overall unsafe set is the union ⇒ we take the minimum value.\n",
    "    \"\"\"\n",
    "    x, y, _ = state\n",
    "    T = remaining_steps * dt\n",
    "    inflated_r = obs_radius + v_max * T\n",
    "    dists = [np.hypot(x - ox, y - oy) - inflated_r for ox, oy in obstacles]\n",
    "    return min(dists)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "#  MPPI controller with HJ safety term\n",
    "# ---------------------------------------------------------------------------\n",
    "class SafeMPPIController:\n",
    "    def __init__(self,\n",
    "                 dynamics_func,\n",
    "                 dt: float,\n",
    "                 goal: np.ndarray,\n",
    "                 horizon: int = 20,\n",
    "                 n_samples: int = 100,\n",
    "                 lam: float = 1.0,\n",
    "                 noise_scale: float = 0.3,\n",
    "                 obstacle_list: list[np.ndarray] | None = None,\n",
    "                 obstacle_radius: float = 0.5,\n",
    "                 collision_penalty: float = 1e6,\n",
    "                 v_max: float = 1.0):\n",
    "        self.dynamics = dynamics_func\n",
    "        self.dt = dt\n",
    "        self.goal = goal\n",
    "        self.H = horizon\n",
    "        self.N = n_samples\n",
    "        self.lam = lam\n",
    "        self.noise_scale = noise_scale\n",
    "        self.u_nom = np.zeros((horizon, 2))\n",
    "        self.obstacles = obstacle_list or []\n",
    "        self.obs_radius = obstacle_radius\n",
    "        self.collision_penalty = collision_penalty\n",
    "        self.v_max = v_max\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    #  Cost of a single control sequence (rollout)\n",
    "    # ---------------------------------------------------------------------\n",
    "    def _trajectory_cost(self, x0: np.ndarray, u_seq: np.ndarray) -> float:\n",
    "        cost = 0.0\n",
    "        x = x0.copy()\n",
    "        for k, u in enumerate(u_seq):\n",
    "            # propagate one step\n",
    "            x = self.dynamics(x, u, self.dt)\n",
    "\n",
    "            # goal‑seeking term (Euclidean distance in position)\n",
    "            cost += np.linalg.norm(x[:2] - self.goal)\n",
    "\n",
    "            # HJ safety term (penalise tubes that intersect obstacles)\n",
    "            V = hj_value(x, self.obstacles, self.obs_radius,\n",
    "                         self.v_max, self.H - k, self.dt)\n",
    "            if V < 0:\n",
    "                cost += self.collision_penalty  # inside unsafe tube\n",
    "        return cost\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    #  Main MPPI step\n",
    "    # ---------------------------------------------------------------------\n",
    "    def step(self, x0: np.ndarray) -> np.ndarray:\n",
    "        # Sample noisy control sequences around the nominal (shape: N × H × 2)\n",
    "        noise = self.noise_scale * np.random.randn(self.N, self.H, 2)\n",
    "        u_rollouts = self.u_nom[None, :, :] + noise\n",
    "\n",
    "        # Evaluate cost of each rollout\n",
    "        costs = np.array([self._trajectory_cost(x0, us) for us in u_rollouts])\n",
    "\n",
    "        # Softmin weighting (temperature = self.lam)\n",
    "        weights = np.exp(-costs / self.lam)\n",
    "        weights_sum = weights.sum()\n",
    "        if weights_sum == 0 or np.isnan(weights_sum):\n",
    "            weights = np.full_like(weights, 1.0 / len(weights))  # fallback\n",
    "        else:\n",
    "            weights /= weights_sum\n",
    "\n",
    "        # Compute optimal first control via importance sampling\n",
    "        u0 = np.tensordot(weights, u_rollouts[:, 0], axes=1)  # shape (2,)\n",
    "\n",
    "        # Shift nominal sequence and append the new tail element\n",
    "        self.u_nom = np.vstack([self.u_nom[1:], u0])\n",
    "        return u0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Environment setup ----------------------------------------------------\n",
    "    dt = 0.1\n",
    "    sim_steps = 150\n",
    "    v_max = 0.8          # assumed speed limit for HJ tube\n",
    "\n",
    "    start_state = np.array([-2.0, -1.0, 0.0])\n",
    "    goal_location = np.array([5.0, 0.0])\n",
    "\n",
    "    obstacle_radius = 0.5\n",
    "    obstacles = [np.array([1.0, 0.0]), np.array([3.0, -0.5])]\n",
    "\n",
    "    # Controller -----------------------------------------------------------\n",
    "    mppi = SafeMPPIController(\n",
    "        dynamics_func=unicycle_dynamics,\n",
    "        dt=dt,\n",
    "        goal=goal_location,\n",
    "        horizon=10,\n",
    "        n_samples=100,\n",
    "        lam=0.6,\n",
    "        noise_scale=0.2,\n",
    "        obstacle_list=obstacles,\n",
    "        obstacle_radius=obstacle_radius,\n",
    "        v_max=v_max,\n",
    "    )\n",
    "\n",
    "    np.random.seed(10)  # reproducibility\n",
    "    state = start_state.copy()\n",
    "    states = [state]\n",
    "\n",
    "    for _ in range(sim_steps):\n",
    "        u = mppi.step(state)\n",
    "        state = unicycle_dynamics(state, u, dt)\n",
    "        states.append(state)\n",
    "\n",
    "    states = np.array(states)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(states[:, 0], states[:, 1], linewidth=2, label=\"MPPI + HJ trajectory\")\n",
    "    ax.plot(start_state[0], start_state[1], \"o\", label=\"Start\", markersize=8)\n",
    "    ax.plot(goal_location[0], goal_location[1], \"x\", label=\"Goal\", markersize=8)\n",
    "\n",
    "    ax.scatter([o[0] for o in obstacles],\n",
    "               [o[1] for o in obstacles],\n",
    "               s=(obstacle_radius * 400) ** 2 / 100.0,\n",
    "               alpha=0.3, label=\"Obstacles\")\n",
    "\n",
    "    ax.set_title(\"Unicycle Robot with MPPI and HJ Reachability Safety\")\n",
    "    ax.set_xlabel(\"x position (m)\")\n",
    "    ax.set_ylabel(\"y position (m)\")\n",
    "    ax.axis(\"equal\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d149c6-abb0-4202-9032-de0430d6bba4",
   "metadata": {},
   "source": [
    "### Integrate safety filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9fcc0-2028-40e8-82ba-5e0a99d348ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unicycle_mppi_safety.py\n",
    "\"\"\"\n",
    "1. **Approximate HJ tube** (fast analytic expansion of obstacle radii)\n",
    "2. **Control‑Barrier‑Function (CBF)** soft penalty\n",
    "3. **Optimal HJ value function** (grid‑based interpolation)\n",
    "4. None\n",
    "\"\"\"\n",
    "\n",
    "class SafetyFilter:\n",
    "    \"\"\"Abstract base.  Returns an additive *cost penalty* (≥0).\"\"\"\n",
    "\n",
    "    def penalty(self, state: np.ndarray, t: float) -> float:  # noqa: D401 – imperative style\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "class ApproxHJSafety(SafetyFilter):\n",
    "    \"\"\"Analytic backward‑reachable tube: r_i + v_max·(T − t).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        obstacles: List[np.ndarray],\n",
    "        radius: float,\n",
    "        v_max: float,\n",
    "        horizon: float,\n",
    "        collision_penalty: float = 1e6,\n",
    "    ) -> None:\n",
    "        self.obstacles = obstacles\n",
    "        self.r = radius\n",
    "        self.v_max = v_max\n",
    "        self.T = horizon\n",
    "        self.coll_pen = collision_penalty\n",
    "\n",
    "    def penalty(self, state: np.ndarray, t: float) -> float:\n",
    "        x, y, _ = state\n",
    "        tube = self.r + self.v_max * (self.T - t)\n",
    "        for p in self.obstacles:\n",
    "            if np.hypot(x - p[0], y - p[1]) < tube:\n",
    "                return self.coll_pen\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "class CBFSafety(SafetyFilter):\n",
    "    \"\"\"Soft barrier cost:   h(x)=‖p−p_obs‖² − r²  ;  cost = κ / h  if h>0 else coll_pen\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        obstacles: List[np.ndarray],\n",
    "        radius: float,\n",
    "        kappa: float = 1.0,\n",
    "        collision_penalty: float = 1e6,\n",
    "    ) -> None:\n",
    "        self.obstacles = obstacles\n",
    "        self.r2 = radius**2\n",
    "        self.kappa = kappa\n",
    "        self.coll_pen = collision_penalty\n",
    "\n",
    "    def penalty(self, state: np.ndarray, t: float) -> float:  # noqa: D401\n",
    "        x, y, _ = state\n",
    "        for p in self.obstacles:\n",
    "            h = (x - p[0]) ** 2 + (y - p[1]) ** 2 - self.r2\n",
    "            if h <= 0:\n",
    "                return self.coll_pen\n",
    "            return self.kappa / h  # larger cost near boundary\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "class OptHJSafety(SafetyFilter):\n",
    "    \"\"\"Grid‑based optimal HJ value‑function lookup.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value_fn : Callable[[float, float], float]\n",
    "        Pre‑computed V(x, y) > 0 ⇒ safe.  Could be an `scipy.interpolate` object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        value_fn: Callable[[float, float], float],\n",
    "        collision_penalty: float = 1e6,\n",
    "    ) -> None:\n",
    "        self.V = value_fn\n",
    "        self.coll_pen = collision_penalty\n",
    "\n",
    "    def penalty(self, state: np.ndarray, t: float) -> float:  # noqa: D401\n",
    "        x, y, _ = state\n",
    "        return 0.0 if self.V(x, y) > 0 else self.coll_pen\n",
    "\n",
    "class MPPIController:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dynamics: Callable[[np.ndarray, np.ndarray, float], np.ndarray],\n",
    "        dt: float,\n",
    "        goal: np.ndarray,\n",
    "        horizon: int = 20,\n",
    "        n_samples: int = 100,\n",
    "        lam: float = 1.0,\n",
    "        noise_scale: float = 0.3,\n",
    "        safety_filter: SafetyFilter | None = None,\n",
    "        collision_penalty: float = 1e6,\n",
    "    ) -> None:\n",
    "        self.dyn = dynamics\n",
    "        self.dt = dt\n",
    "        self.goal = goal\n",
    "        self.H = horizon\n",
    "        self.N = n_samples\n",
    "        self.lam = lam\n",
    "        self.noise_scale = noise_scale\n",
    "        self.u_nom = np.zeros((horizon, 2))\n",
    "        self.filter = safety_filter or SafetyFilter()\n",
    "        self.coll_pen = collision_penalty\n",
    "\n",
    "    # ......................................................................\n",
    "    # Internal helpers\n",
    "    # ......................................................................\n",
    "\n",
    "    def _rollout_cost(self, x0: np.ndarray, u_seq: np.ndarray) -> float:\n",
    "        cost = 0.0\n",
    "        x = x0.copy()\n",
    "        for k, u in enumerate(u_seq):\n",
    "            x = self.dyn(x, u, self.dt)\n",
    "            cost += np.linalg.norm(x[:2] - self.goal)  # tracking term\n",
    "            cost += self.filter.penalty(x, k * self.dt)  # safety term\n",
    "        return cost\n",
    "\n",
    "    def step(self, x0: np.ndarray) -> np.ndarray:\n",
    "        noise = self.noise_scale * np.random.randn(self.N, self.H, 2)\n",
    "        rollouts = self.u_nom[None, :, :] + noise\n",
    "        costs = np.array([self._rollout_cost(x0, u) for u in rollouts])\n",
    "\n",
    "        weights = np.exp(-costs / self.lam)\n",
    "        w_sum = np.sum(weights)\n",
    "        if w_sum == 0 or np.isnan(w_sum):\n",
    "            weights = np.ones_like(weights) / len(weights)\n",
    "        else:\n",
    "            weights /= w_sum\n",
    "\n",
    "        u0 = np.sum(weights[:, None] * rollouts[:, 0], axis=0)\n",
    "        self.u_nom = np.vstack([self.u_nom[1:], u0])  # shift\n",
    "        return u0\n",
    "\n",
    "def make_safety_filter(\n",
    "    mode: Literal[\"approx_hj\", \"cbf\", \"opt_hj\", None],\n",
    "    *,\n",
    "    obstacles: List[np.ndarray],\n",
    "    radius: float,\n",
    "    horizon: float,\n",
    "    dt: float,\n",
    "    v_max: float = 1.0,\n",
    "    kappa: float = 1.0,\n",
    "    value_fn: Callable[[float, float], float] | None = None,\n",
    "    collision_penalty: float = 1e6,\n",
    ") -> SafetyFilter | None:\n",
    "    if mode is None:\n",
    "        return None\n",
    "    if mode == \"approx_hj\":\n",
    "        return ApproxHJSafety(obstacles, radius, v_max, horizon * dt, collision_penalty)\n",
    "    if mode == \"cbf\":\n",
    "        return CBFSafety(obstacles, radius, kappa, collision_penalty)\n",
    "    if mode == \"opt_hj\":\n",
    "        if value_fn is None:\n",
    "            raise ValueError(\"`value_fn` must be provided for opt_hj mode.\")\n",
    "        return OptHJSafety(value_fn, collision_penalty)\n",
    "    raise ValueError(f\"Unknown safety mode: {mode}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Environment -----------------------------------------------------------\n",
    "    dt = 0.1\n",
    "    sim_steps = 150\n",
    "    start_state = np.array([-2.0, -1.0, 0.0])\n",
    "    goal = np.array([5.0, 0.0])\n",
    "\n",
    "    obstacle_radius = 0.5\n",
    "    p1 = np.array([1.0, 0.0])\n",
    "    p2 = np.array([3.0, -0.5])\n",
    "    obstacles = [p1, p2]\n",
    "\n",
    "    # Choose safety filter --------------------------------------------------\n",
    "    safety = make_safety_filter(\n",
    "        \"cbf\",  # change to \"cbf\", \"opt_hj\", or None\n",
    "        obstacles=obstacles,\n",
    "        radius=obstacle_radius,\n",
    "        horizon=10,\n",
    "        dt=dt,\n",
    "        v_max=1.2,\n",
    "    )\n",
    "\n",
    "    # Controller ------------------------------------------------------------\n",
    "    mppi = MPPIController(\n",
    "        dynamics=unicycle_dynamics,\n",
    "        dt=dt,\n",
    "        goal=goal,\n",
    "        horizon=10,\n",
    "        n_samples=100,\n",
    "        lam=0.6,\n",
    "        noise_scale=0.2,\n",
    "        safety_filter=safety,\n",
    "    )\n",
    "\n",
    "    # Simulate --------------------------------------------------------------\n",
    "    np.random.seed(16)\n",
    "    x = start_state.copy()\n",
    "    traj = [x]\n",
    "    for _ in range(sim_steps):\n",
    "        u = mppi.step(x)\n",
    "        x = unicycle_dynamics(x, u, dt)\n",
    "        traj.append(x)\n",
    "    traj = np.array(traj)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(traj[:, 0], traj[:, 1], label=\"MPPI trajectory\")\n",
    "    ax.plot(start_state[0], start_state[1], \"o\", label=\"Start\")\n",
    "    ax.plot(goal[0], goal[1], \"x\", label=\"Goal\")\n",
    "    ax.scatter([p1[0], p2[0]], [p1[1], p2[1]], s=600, alpha=0.3, label=\"Obstacles\")\n",
    "    ax.axis(\"equal\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Unicycle MPPI with Safety Filter\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5d411-6620-40c1-9309-6c5517a1e97f",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d013e9-302c-41bb-a9c8-1459d66868c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt          = 0.1\n",
    "sim_steps   = 150\n",
    "\n",
    "start_state = np.array([-2.0, -1.0, 0.0])\n",
    "goal        = np.array([5.0,  0.0])\n",
    "\n",
    "obstacles         = [np.array([1.0, 0.0]), np.array([3.0, -0.5])]\n",
    "obstacle_radius   = 0.2\n",
    "v_max             = 1.0               # speed bound for HJ tube\n",
    "\n",
    "horizon           = 10\n",
    "n_samples         = 100\n",
    "lam               = 0.6\n",
    "noise_scale       = 0.2\n",
    "\n",
    "collision_penalty = 1e6\n",
    "kappa_cbf         = 1.0               # CBF gain\n",
    "kappa_scbf        = 5.0               # Smooth‑CBF gain\n",
    "\n",
    "np.random.seed(42)                    # overall reproducibility\n",
    "\n",
    "# ============================================================\n",
    "# ------------------ UNICYCLE DYNAMICS -----------------------\n",
    "# ============================================================\n",
    "def unicycle_dynamics(state, control, dt):\n",
    "    x, y, th = state\n",
    "    v, w     = control\n",
    "    return np.array([\n",
    "        x  + v*np.cos(th)*dt,\n",
    "        y  + v*np.sin(th)*dt,\n",
    "        th + w*dt\n",
    "    ])\n",
    "\n",
    "# ============================================================\n",
    "# ------------------ SAFETY FILTERS --------------------------\n",
    "# ============================================================\n",
    "class SafetyFilter:\n",
    "    def penalty(self, state: np.ndarray, t: float) -> float:\n",
    "        return 0.0\n",
    "\n",
    "class ApproxHJSafety(SafetyFilter):\n",
    "    \"\"\"Inflated obstacle tube: r + v_max (T‑t).\"\"\"\n",
    "    def __init__(self, obstacles, radius, v_max, horizon_T, penalty=1e6):\n",
    "        self.obs, self.r, self.vmax, self.T, self.pen = obstacles, radius, v_max, horizon_T, penalty\n",
    "    def penalty(self, state, t):\n",
    "        x, y, _ = state\n",
    "        tube = self.r + self.vmax * (self.T - t)\n",
    "        return self.pen if any(np.hypot(x-ox, y-oy) < tube for ox,oy in self.obs) else 0.0\n",
    "\n",
    "class CBFSafety(SafetyFilter):\n",
    "    \"\"\"1/h soft penalty (standard reciprocal CBF).\"\"\"\n",
    "    def __init__(self, obstacles, radius, kappa=1.0, penalty=1e6):\n",
    "        self.obs, self.r2, self.kappa, self.pen = obstacles, radius**2, kappa, penalty\n",
    "    def penalty(self, state, t):\n",
    "        x, y, _ = state\n",
    "        for ox, oy in self.obs:\n",
    "            h = (x-ox)**2 + (y-oy)**2 - self.r2\n",
    "            if h <= 0:\n",
    "                return self.pen\n",
    "            return self.kappa / h\n",
    "        return 0.0\n",
    "\n",
    "class SCBFSafety(SafetyFilter):\n",
    "    \"\"\"Smooth‑CBF: quadratic penalty inside r‑tube, softer outside.\"\"\"\n",
    "    def __init__(self, obstacles, radius, kappa=5.0, penalty=1e6):\n",
    "        self.obs, self.r, self.kappa, self.pen = obstacles, radius, kappa, penalty\n",
    "    def penalty(self, state, t):\n",
    "        x, y, _ = state\n",
    "        for ox, oy in self.obs:\n",
    "            dist = np.hypot(x-ox, y-oy)\n",
    "            if dist < self.r:\n",
    "                return self.pen\n",
    "            return self.kappa * (self.r / dist)**2\n",
    "        return 0.0\n",
    "\n",
    "class OptHJSafety(SafetyFilter):\n",
    "    \"\"\"Placeholder optimal HJ: signed distance to nearest obstacle.\"\"\"\n",
    "    def __init__(self, obstacles, radius, penalty=1e6):\n",
    "        self.obs, self.r, self.pen = obstacles, radius, penalty\n",
    "    def value(self, x, y):\n",
    "        return min(np.hypot(x-ox, y-oy) - self.r for ox, oy in self.obs)\n",
    "    def penalty(self, state, t):\n",
    "        x, y, _ = state\n",
    "        return 0.0 if self.value(x, y) > 0 else self.pen\n",
    "\n",
    "class CombinedSafety(SafetyFilter):\n",
    "    \"\"\"Sum penalties from multiple filters.\"\"\"\n",
    "    def __init__(self, filters):\n",
    "        self.filters = filters\n",
    "    def penalty(self, state, t):\n",
    "        return sum(f.penalty(state, t) for f in self.filters)\n",
    "\n",
    "# ============================================================\n",
    "# ------------------ MPPI CONTROLLER -------------------------\n",
    "# ============================================================\n",
    "class MPPI:\n",
    "    def __init__(self, dynamics, dt, goal, horizon, n_samples,\n",
    "                 lam, noise_scale, safety: SafetyFilter|None):\n",
    "        self.dyn    = dynamics\n",
    "        self.dt     = dt\n",
    "        self.goal   = goal\n",
    "        self.H      = horizon\n",
    "        self.N      = n_samples\n",
    "        self.lam    = lam\n",
    "        self.noise  = noise_scale\n",
    "        self.safety = safety or SafetyFilter()\n",
    "        self.u_nom  = np.zeros((horizon, 2))\n",
    "\n",
    "    def _rollout_cost(self, x0, u_seq):\n",
    "        x = x0.copy()\n",
    "        cost = 0.0\n",
    "        for k, u in enumerate(u_seq):\n",
    "            x = self.dyn(x, u, self.dt)\n",
    "            cost += np.linalg.norm(x[:2] - self.goal)\n",
    "            cost += self.safety.penalty(x, k*self.dt)\n",
    "        return cost\n",
    "\n",
    "    def step(self, x0):\n",
    "        noise   = self.noise * np.random.randn(self.N, self.H, 2)\n",
    "        rollouts= self.u_nom[None,:,:] + noise\n",
    "        costs   = np.array([self._rollout_cost(x0, u) for u in rollouts])\n",
    "\n",
    "        w = np.exp(-costs / self.lam)\n",
    "        w_sum = w.sum()\n",
    "        w = w / w_sum if w_sum > 0 and not np.isnan(w_sum) else np.ones_like(w) / len(w)\n",
    "\n",
    "        u0 = np.tensordot(w, rollouts[:,0], axes=1)\n",
    "        self.u_nom = np.vstack([self.u_nom[1:], u0])\n",
    "        return u0\n",
    "\n",
    "def simulate(controller, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    x = start_state.copy()\n",
    "    traj = [x]\n",
    "    for _ in range(sim_steps):\n",
    "        u = controller.step(x)\n",
    "        x = unicycle_dynamics(x, u, dt)\n",
    "        traj.append(x)\n",
    "    return np.array(traj)\n",
    "\n",
    "# ============================================================\n",
    "# ------------------ BUILD CONTROLLERS -----------------------\n",
    "# ============================================================\n",
    "T_horizon_sec = horizon * dt\n",
    "\n",
    "hj_filter    = ApproxHJSafety(obstacles, obstacle_radius, v_max, T_horizon_sec, collision_penalty)\n",
    "cbf_filter   = CBFSafety(obstacles, obstacle_radius, kappa_cbf, collision_penalty)\n",
    "scbf_filter  = SCBFSafety(obstacles, obstacle_radius, kappa_scbf, collision_penalty)\n",
    "opt_hj_filter= OptHJSafety(obstacles, obstacle_radius, collision_penalty)\n",
    "\n",
    "controllers = {\n",
    "    \"Vanilla\":    MPPI(unicycle_dynamics, dt, goal, horizon, n_samples, lam, noise_scale, None),\n",
    "    \"HJ\":         MPPI(unicycle_dynamics, dt, goal, horizon, n_samples, lam, noise_scale, hj_filter),\n",
    "    \"HJ+CBF\":     MPPI(unicycle_dynamics, dt, goal, horizon, n_samples, lam, noise_scale,\n",
    "                       CombinedSafety([hj_filter, cbf_filter])),\n",
    "    \"HJ+OptHJ\":   MPPI(unicycle_dynamics, dt, goal, horizon, n_samples, lam, noise_scale,\n",
    "                       CombinedSafety([hj_filter, opt_hj_filter])),\n",
    "    \"HJ+SCBF\":    MPPI(unicycle_dynamics, dt, goal, horizon, n_samples, lam, noise_scale,\n",
    "                       CombinedSafety([hj_filter, scbf_filter]))\n",
    "}\n",
    "\n",
    "trajectories = {label: simulate(ctrl, seed=42) for label, ctrl in controllers.items()}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "for label, traj in trajectories.items():\n",
    "    ax.plot(traj[:,0], traj[:,1], label=label)\n",
    "\n",
    "ax.plot(start_state[0], start_state[1], marker='o', linestyle='', markersize=8, label='Start')\n",
    "ax.plot(goal[0], goal[1], marker='x', linestyle='', markersize=8, label='Goal')\n",
    "\n",
    "ax.scatter([p[0] for p in obstacles], [p[1] for p in obstacles],\n",
    "           s=(obstacle_radius*400)**2/100.0, alpha=0.3, label='Obstacles')\n",
    "\n",
    "ax.set_title(\"Unicycle MPPI: Safety Filter Comparison\")\n",
    "ax.set_xlabel(\"x position (m)\")\n",
    "ax.set_ylabel(\"y position (m)\")\n",
    "ax.axis('equal')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d51fd-de30-44dd-915e-f041e2d25667",
   "metadata": {},
   "source": [
    "### Success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19154b5-8d16-4afa-8786-074680aaacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# -------- SUCCESS-RATE MONTE-CARLO + PROGRESS BAR -----------\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm                      # ▶ live progress bar\n",
    "\n",
    "# ---------- tweakables -------------------------------------------------------\n",
    "N_TRIALS        = 10        # number of random seeds\n",
    "GOAL_RADIUS     = 0.20       # success if final ≤ 20 cm from goal\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def reached_goal(traj, goal, tol):\n",
    "    \"\"\"True if final xy-distance is within `tol`.\"\"\"\n",
    "    return np.linalg.norm(traj[-1, :2] - goal) <= tol\n",
    "\n",
    "\n",
    "def hit_obstacle(traj, obstacles, r):\n",
    "    \"\"\"True if *any* state enters an obstacle of radius r.\"\"\"\n",
    "    for x, y, _ in traj:\n",
    "        if any(np.hypot(x - ox, y - oy) < r for ox, oy in obstacles):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# --- map each label to a *factory* that builds a fresh MPPI every trial ------\n",
    "controller_factories = {\n",
    "    \"Vanilla\":   lambda: MPPI(unicycle_dynamics, dt, goal, horizon,\n",
    "                              n_samples, lam, noise_scale, None),\n",
    "    \"HJ\":        lambda: MPPI(unicycle_dynamics, dt, goal, horizon,\n",
    "                              n_samples, lam, noise_scale, hj_filter),\n",
    "    \"HJ+CBF\":    lambda: MPPI(unicycle_dynamics, dt, goal, horizon, n_samples,\n",
    "                              lam, noise_scale, CombinedSafety([hj_filter, cbf_filter])),\n",
    "    \"HJ+OptHJ\":  lambda: MPPI(unicycle_dynamics, dt, goal, horizon, n_samples,\n",
    "                              lam, noise_scale, CombinedSafety([hj_filter, opt_hj_filter])),\n",
    "    \"HJ+SCBF\":   lambda: MPPI(unicycle_dynamics, dt, goal, horizon, n_samples,\n",
    "                              lam, noise_scale, CombinedSafety([hj_filter, scbf_filter])),\n",
    "}\n",
    "\n",
    "success_counts = {label: 0 for label in controller_factories}\n",
    "\n",
    "# --------------------------- Monte-Carlo loop -------------------------------\n",
    "for trial in tqdm(range(N_TRIALS), desc=\"Simulations\"):\n",
    "    seed = 1000 + trial                     # different seed each run\n",
    "    for label, factory in controller_factories.items():\n",
    "        ctrl  = factory()                   # fresh controller (no memory leak)\n",
    "        traj  = simulate(ctrl, seed=seed)\n",
    "        ok    = reached_goal(traj, goal, GOAL_RADIUS) and \\\n",
    "                not hit_obstacle(traj, obstacles, obstacle_radius)\n",
    "        success_counts[label] += int(ok)\n",
    "\n",
    "# convert to rates 0 – 1\n",
    "success_rates = {lbl: c / N_TRIALS for lbl, c in success_counts.items()}\n",
    "\n",
    "# --------------------------- “progress-bar” plot -----------------------------\n",
    "plt.figure(figsize=(8, 4))\n",
    "labels = list(success_rates.keys())\n",
    "rates  = [success_rates[lbl] for lbl in labels]\n",
    "\n",
    "plt.barh(labels, rates)            # bars grow left→right like progress bars\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel(\"Success rate (fraction of {} trials)\".format(N_TRIALS))\n",
    "plt.title(\"MPPI Controller Success Rates\")\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54201a53-e3f5-49b0-938c-869f81f9a00c",
   "metadata": {},
   "source": [
    "### Collision rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9fbc57-9ba8-4f10-b0a2-5879c6324503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a82dc-671d-41c6-a8ed-07a3e5be0dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
